# classic-ml-fraud-detection
# ğŸ›¡ï¸ Credit Card Fraud Detection

End-to-End Applied Machine Learning Project

ğŸ“Œ Project Overview

Credit card fraud costs financial institutions billions of dollars annually.
This project builds and evaluates machine learning models to detect fraudulent transactions while balancing false positives (blocking real customers) and false negatives (missing fraud).

The goal is not only to achieve strong predictive performance, but to demonstrate an applied data science workflow from data ingestion â†’ modeling â†’ evaluation â†’ interpretation.

ğŸ¯ Business Problem

Financial institutions must:

Detect fraud as early as possible

Minimize disruption to legitimate customers

Handle extreme class imbalance (fraud â‰ª non-fraud)

This project answers:

Can we reliably identify fraudulent transactions while maintaining an acceptable customer experience?

ğŸ“Š Dataset

Source: Public credit card transaction dataset

Size: ~280,000 transactions

Target variable: Class

0 â†’ Legitimate transaction

1 â†’ Fraudulent transaction

Key challenge: Fraud represents <1% of all transactions

All features are numerical and anonymized for privacy.

ğŸ” Exploratory Data Analysis (EDA)

Key findings:

Severe class imbalance requires careful evaluation metrics

Standard accuracy is misleading for this problem

Precision, Recall, F1-Score, and ROC-AUC are more meaningful

EDA steps include:

Class distribution analysis

Feature scaling

Train/validation split with stratification

ğŸ§  Modeling Approach
Baseline Model: Logistic Regression

Serves as a transparent, interpretable baseline

Helps establish a performance floor

Suitable for regulated financial environments

Advanced Model: XGBoost

Handles non-linear feature interactions

More robust to complex decision boundaries

Often used in real-world fraud systems

Both models were trained using:

Proper train/test splits

Feature scaling where required

Class imbalance-aware evaluation

ğŸ“ˆ Model Evaluation
Metrics Used

Because of class imbalance, we prioritize:

Recall (Fraud class) â†’ catching fraud

Precision â†’ minimizing false alerts

ROC-AUC â†’ overall ranking performance

Results Summary (Example)
Model	ROC-AUC	Recall (Fraud)	Precision
Logistic Regression	Strong baseline	Moderate	High
XGBoost	Improved	Higher	Competitive

XGBoost achieved higher fraud recall while maintaining reasonable precision, making it more suitable for production use.

ğŸ” Interpretation & Business Insights
Key Trade-offs

Increasing fraud recall reduces missed fraud

But may increase false positives â†’ customer friction

Business Recommendation

XGBoost is preferred when fraud loss outweighs customer inconvenience

Logistic Regression may be chosen where interpretability is required

Threshold tuning allows institutions to customize risk tolerance based on business priorities.

ğŸ§ª Project Structure
classic-ml-fraud-detection/
â”‚
â”œâ”€â”€ data/                 # Raw and processed datasets
â”œâ”€â”€ notebooks/            # EDA and modeling notebooks
â”œâ”€â”€ src/                  # Reusable preprocessing & modeling code
â”œâ”€â”€ models/               # Saved model artifacts
â”œâ”€â”€ assets/               # Visualizations and figures
â””â”€â”€ README.md             # Project documentation

ğŸ› ï¸ Tech Stack

Python

Pandas / NumPy

Scikit-Learn

XGBoost

Matplotlib / Seaborn

Jupyter Notebook

ğŸš€ Future Improvements

Threshold optimization based on business cost functions

SHAP values for advanced model interpretability

Real-time inference simulation

Model monitoring & drift detection

ğŸ“Œ Key Takeaway

This project demonstrates how applied data science goes beyond model accuracy â€” balancing business constraints, risk, and interpretability to deliver real-world value.

ğŸ‘¤ Author

Juante Wilson
Aspiring Applied Data Scientist / Machine Learning Engineer
GitHub: https://github.com/Juantew




    
